model:
  class_path: fmtransfer.tasks.FMTransfer
  init_args:
    decoder:
      class_path: fmtransfer.models.decoders.GRUDecoder
      init_args:
        hidden_size: 128
        input_size: 2
    projection:
      class_path: torch.nn.Linear
      init_args:
        in_features: 128
        out_features: 6
# Sigmoid wont' work with a shallow mlp in the output.
#    output_activation:
#      class_path: torch.nn.Sigmoid
    loss_fn:
      class_path: torch.nn.L1Loss
      init_args:
        reduction: mean
    float32_matmul_precision: 'high'
    optimizer:
      class_path: torch.optim.Adam
      init_args:
        lr: 0.001
    lr_scheduler:
      class_path: torch.optim.lr_scheduler.ExponentialLR
      init_args:
        gamma: 0.98
    lr_scheduler_steps: 10000
data: data/data_single.yaml
trainer:
  devices: [0]
  accelerator: gpu
  min_steps: 120000
  max_steps: 120000
  logger:
    class_path: pytorch_lightning.loggers.CSVLogger
    init_args:
      name: paper_runs
      save_dir: ./logs
  callbacks:
    - class_path: fmtransfer.callbacks.TestMetricsCallback # Only works with linear envelope generation
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
    - class_path: fmtransfer.callbacks.TS_ExportModelCallback
seed_everything: 396818285
